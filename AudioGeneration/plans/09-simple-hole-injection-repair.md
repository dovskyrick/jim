# 09 - Simple Hole Injection Repair (Audio Surgery)

**Status:** Proposed  
**Priority:** High  
**Date:** December 29, 2025  
**Supersedes:** Parts of plan 08 (simplifies reconstruction approach)

## Simplified Approach

Instead of extracting segments and rebuilding, we:
1. Take the existing lesson audio **as-is** (with holes = silent segments)
2. **Inject** the repaired vocab audio at the precise timestamp where the hole is
3. **Don't remove** the original silence - just play new audio over it
4. Shift timestamps of subsequent segments (metadata only)

**Analogy:** Like dubbing over a muted section of a video - the video keeps playing, we just add audio where there was none.

## Technical Implementation

### Step 1: Metadata During Generation

When generating a lesson, save metadata JSON:

**File:** `lessons-audio/{language}/{level}/{lessonId}.metadata.json`

```json
{
  "lessonId": "lesson1",
  "languageId": "greek",
  "levelId": "level1",
  "generatedAt": "2025-12-29T10:30:00.000Z",
  "audioFile": "lesson1.mp3",
  "totalDurationMs": 125430,
  "segments": [
    {
      "index": 0,
      "startMs": 0,
      "durationMs": 3000,
      "type": "silence"
    },
    {
      "index": 1,
      "startMs": 3000,
      "durationMs": 1250,
      "type": "vocab",
      "text": "ŒìŒµŒπŒ± œÉŒøœÖ",
      "vocabFile": "vocab-audio/00001.mp3",
      "normalized": "ŒìŒµŒπŒ± œÉŒøœÖ"
    },
    {
      "index": 2,
      "startMs": 4250,
      "durationMs": 3000,
      "type": "silence"
    },
    {
      "index": 3,
      "startMs": 7250,
      "durationMs": 1650,
      "type": "tts",
      "text": "ŒìŒµŒπŒ± œÉŒ±œÇ"
    }
  ],
  "vocabDependencies": {
    "vocab-audio/00001.mp3": {
      "text": "ŒìŒµŒπŒ± œÉŒøœÖ",
      "segments": [1, 15, 23]
    },
    "vocab-audio/00005.mp3": {
      "text": "ŒïœÖœáŒ±œÅŒπœÉœÑœé", 
      "segments": [8, 42]
    }
  }
}
```

### Step 2: Detect Which Lessons Need Repair

After `vocab-repair.ts` runs, it returns list of repaired files:

```typescript
interface RepairResult {
  repairedFiles: Array<{
    filename: string;      // e.g., "00001.mp3"
    text: string;          // e.g., "ŒìŒµŒπŒ± œÉŒøœÖ"
    audioPath: string;     // full path to vocab file
  }>;
}
```

**Lesson Reconstructor** scans metadata files:

```typescript
async function findAffectedLessons(
  repairedVocabFiles: string[],
  languageId: string,
  levelId: string
): Promise<LessonRepairJob[]> {
  const jobs: LessonRepairJob[] = [];
  const metadataDir = `lessons-audio/${languageId}/${levelId}`;
  
  // Find all .metadata.json files
  const metadataFiles = fs.readdirSync(metadataDir)
    .filter(f => f.endsWith('.metadata.json'));
  
  for (const metaFile of metadataFiles) {
    const metadata = JSON.parse(fs.readFileSync(metaFile, 'utf-8'));
    
    // Check if this lesson uses any repaired vocab
    const affectedSegments: number[] = [];
    
    for (const repairedFile of repairedVocabFiles) {
      const vocabKey = `vocab-audio/${repairedFile}`;
      
      if (metadata.vocabDependencies[vocabKey]) {
        affectedSegments.push(...metadata.vocabDependencies[vocabKey].segments);
      }
    }
    
    if (affectedSegments.length > 0) {
      jobs.push({
        lessonId: metadata.lessonId,
        audioFile: `lessons-audio/${languageId}/${levelId}/${metadata.audioFile}`,
        metadata: metadata,
        holesIndices: affectedSegments.sort((a, b) => a - b)
      });
    }
  }
  
  return jobs;
}
```

### Step 3: Inject Audio at Precise Timestamps

For each hole, we need to insert audio. FFmpeg approach depends on strategy:

#### Option A: Audio Overlay (Simpler - RECOMMENDED)

**Concept:** Mix new audio on top of existing track at specific timestamp.

```typescript
async function injectAudioAtTimestamp(
  originalAudio: string,
  injectAudio: string,
  timestampMs: number,
  outputAudio: string
): Promise<void> {
  // Convert ms to seconds with 3 decimal precision
  const timestampSec = (timestampMs / 1000).toFixed(3);
  
  // FFmpeg overlay/mix command
  // This plays injectAudio starting at timestampSec over the originalAudio
  return new Promise((resolve, reject) => {
    ffmpeg()
      .input(originalAudio)
      .input(injectAudio)
      .complexFilter([
        // Delay the second input to start at the right time
        `[1:a]adelay=${timestampMs}|${timestampMs}[delayed]`,
        // Mix both audio streams
        `[0:a][delayed]amix=inputs=2:duration=longest[outa]`
      ])
      .outputOptions('-map', '[outa]')
      .audioCodec('libmp3lame')
      .audioBitrate('128k')
      .output(outputAudio)
      .on('end', () => resolve())
      .on('error', (err) => reject(err))
      .run();
  });
}
```

**Pros:**
- ‚úÖ One FFmpeg command per hole
- ‚úÖ No need to split/rejoin
- ‚úÖ Timestamps stay accurate
- ‚úÖ Original silence preserved (harmless)

**Cons:**
- ‚ö†Ô∏è If multiple holes, need multiple passes (or complex filter)

#### Option B: Sequential Overlay for Multiple Holes

For a lesson with multiple holes, do multiple overlays:

```typescript
async function repairLessonAudio(
  job: LessonRepairJob,
  vocabManager: VocabManager
): Promise<void> {
  let currentAudio = job.audioFile;
  let tempCounter = 0;
  
  console.log(`üîß Repairing ${job.lessonId}: ${job.holesIndices.length} holes`);
  
  // Process holes in order (earliest first)
  for (const segmentIndex of job.holesIndices) {
    const segment = job.metadata.segments[segmentIndex];
    
    if (segment.type !== 'vocab') {
      console.log(`   ‚è≠Ô∏è  Skipping segment ${segmentIndex} (not vocab)`);
      continue;
    }
    
    // Get the repaired audio from vocab library
    const vocabAudioPath = path.join(
      'lessons-content',
      job.metadata.languageId,
      job.metadata.levelId,
      segment.vocabFile
    );
    
    if (!fs.existsSync(vocabAudioPath)) {
      console.log(`   ‚ö†Ô∏è  Vocab file not found: ${vocabAudioPath}`);
      continue;
    }
    
    console.log(`   üíâ Injecting at ${segment.startMs}ms: "${segment.text}"`);
    
    // Create temp output
    const tempOutput = `${currentAudio}.temp${tempCounter}.mp3`;
    tempCounter++;
    
    // Inject audio at this timestamp
    await injectAudioAtTimestamp(
      currentAudio,
      vocabAudioPath,
      segment.startMs,
      tempOutput
    );
    
    // Clean up previous temp if needed
    if (currentAudio !== job.audioFile) {
      fs.unlinkSync(currentAudio);
    }
    
    // Update current audio reference
    currentAudio = tempOutput;
  }
  
  // Replace original with repaired version
  if (currentAudio !== job.audioFile) {
    fs.copyFileSync(currentAudio, job.audioFile);
    fs.unlinkSync(currentAudio);
    console.log(`   ‚úÖ Repaired audio saved: ${job.audioFile}`);
  }
  
  // Update metadata timestamp
  job.metadata.lastRepairedAt = new Date().toISOString();
  job.metadata.repairedSegments = job.holesIndices;
  
  const metadataPath = job.audioFile.replace('.mp3', '.metadata.json');
  fs.writeFileSync(metadataPath, JSON.stringify(job.metadata, null, 2));
}
```

#### Option C: Single Complex Filter (Advanced - OPTIMAL)

Inject all holes in one FFmpeg command:

```typescript
async function repairLessonAudioBatch(
  job: LessonRepairJob,
  vocabManager: VocabManager
): Promise<void> {
  const inputs: string[] = [job.audioFile];
  const filters: string[] = [];
  const inputLabels: string[] = ['[0:a]'];
  
  // Prepare all inject files and delays
  for (let i = 0; i < job.holesIndices.length; i++) {
    const segmentIndex = job.holesIndices[i];
    const segment = job.metadata.segments[segmentIndex];
    
    if (segment.type !== 'vocab') continue;
    
    const vocabPath = path.join(
      'lessons-content',
      job.metadata.languageId,
      job.metadata.levelId,
      segment.vocabFile
    );
    
    inputs.push(vocabPath);
    
    // Create delayed version of this input
    const inputNum = inputs.length - 1;
    const delayMs = segment.startMs;
    filters.push(
      `[${inputNum}:a]adelay=${delayMs}|${delayMs}[delayed${i}]`
    );
    inputLabels.push(`[delayed${i}]`);
  }
  
  // Mix all streams together
  const mixFilter = `${inputLabels.join('')}amix=inputs=${inputLabels.length}:duration=longest[outa]`;
  filters.push(mixFilter);
  
  // Build FFmpeg command
  const command = ffmpeg();
  
  // Add all inputs
  inputs.forEach(input => command.input(input));
  
  // Add complex filter
  command.complexFilter(filters);
  
  // Output configuration
  const outputPath = `${job.audioFile}.repaired.mp3`;
  
  await new Promise((resolve, reject) => {
    command
      .outputOptions('-map', '[outa]')
      .audioCodec('libmp3lame')
      .audioBitrate('128k')
      .output(outputPath)
      .on('end', () => resolve())
      .on('error', (err) => reject(err))
      .run();
  });
  
  // Replace original
  fs.unlinkSync(job.audioFile);
  fs.renameSync(outputPath, job.audioFile);
  
  console.log(`   ‚úÖ Repaired ${job.holesIndices.length} holes in one pass`);
}
```

**This is the BEST approach:**
- ‚úÖ Single FFmpeg call (fastest)
- ‚úÖ All holes fixed simultaneously
- ‚úÖ No quality loss from multiple re-encodes
- ‚úÖ No intermediate temp files

## Code Structure

### New Files

**`src/lesson-reconstructor.ts`**
```typescript
import { VocabManager } from './vocab-manager.js';
import { RepairResult } from './vocab-repair.js';
import ffmpeg from 'fluent-ffmpeg';
import * as fs from 'fs';
import * as path from 'path';

interface LessonMetadata {
  lessonId: string;
  languageId: string;
  levelId: string;
  audioFile: string;
  totalDurationMs: number;
  segments: SegmentInfo[];
  vocabDependencies: Record<string, VocabDependency>;
}

interface SegmentInfo {
  index: number;
  startMs: number;
  durationMs: number;
  type: 'silence' | 'vocab' | 'tts';
  text?: string;
  vocabFile?: string;
  normalized?: string;
}

interface VocabDependency {
  text: string;
  segments: number[];
}

interface LessonRepairJob {
  lessonId: string;
  audioFile: string;
  metadata: LessonMetadata;
  holesIndices: number[];
}

export class LessonReconstructor {
  async reconstructLessons(
    repairResult: RepairResult,
    languageId: string,
    levelId: string
  ): Promise<void> {
    // Find affected lessons
    const jobs = await this.findAffectedLessons(/*...*/);
    
    // Repair each lesson
    for (const job of jobs) {
      await this.repairLessonAudioBatch(job);
    }
  }
  
  private async findAffectedLessons(/*...*/): Promise<LessonRepairJob[]> {
    // Implementation from Step 2
  }
  
  private async repairLessonAudioBatch(/*...*/): Promise<void> {
    // Implementation from Option C
  }
}
```

### Modified Files

**`src/lesson-generator.ts`** - Add metadata saving:

```typescript
async generateLesson(/*...*/): Promise<GeneratedAudio> {
  // ... existing generation code ...
  
  // NEW: Track segment timing during concatenation
  const segments: SegmentInfo[] = [];
  const vocabDeps: Record<string, VocabDependency> = {};
  
  let currentTimeMs = 0;
  
  // Starting silence
  segments.push({
    index: 0,
    startMs: 0,
    durationMs: 3000,
    type: 'silence'
  });
  currentTimeMs = 3000;
  
  // Track each phrase
  for (let i = 0; i < phraseFiles.length; i++) {
    const phraseDurationMs = await this.getAudioDurationMs(phraseFiles[i]);
    
    // Determine source
    let type: 'vocab' | 'tts' = 'tts';
    let vocabFile: string | undefined;
    
    if (/* this phrase came from vocab library */) {
      type = 'vocab';
      vocabFile = /* vocab filename */;
      
      // Track dependency
      if (!vocabDeps[`vocab-audio/${vocabFile}`]) {
        vocabDeps[`vocab-audio/${vocabFile}`] = {
          text: normalizedText,
          segments: []
        };
      }
      vocabDeps[`vocab-audio/${vocabFile}`].segments.push(segments.length);
    }
    
    segments.push({
      index: segments.length,
      startMs: currentTimeMs,
      durationMs: phraseDurationMs,
      type: type,
      text: phrases[i],
      vocabFile: vocabFile,
      normalized: normalizedText
    });
    
    currentTimeMs += phraseDurationMs;
    
    // Add pause
    const pauseMs = (pauseDurations[i] || 3) * 1000;
    segments.push({
      index: segments.length,
      startMs: currentTimeMs,
      durationMs: pauseMs,
      type: 'silence'
    });
    currentTimeMs += pauseMs;
  }
  
  // NEW: Save metadata
  const metadata: LessonMetadata = {
    lessonId: content.lessonId,
    languageId: content.languageId,
    levelId: content.levelId,
    audioFile: `${content.lessonId}.mp3`,
    totalDurationMs: currentTimeMs,
    generatedAt: new Date().toISOString(),
    segments: segments,
    vocabDependencies: vocabDeps
  };
  
  const metadataPath = finalPath.replace('.mp3', '.metadata.json');
  fs.writeFileSync(metadataPath, JSON.stringify(metadata, null, 2));
  console.log(`üíæ Metadata saved: ${metadataPath}`);
  
  // ... existing upload code ...
}

private async getAudioDurationMs(filePath: string): Promise<number> {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(filePath, (err, metadata) => {
      if (err) reject(err);
      else resolve(Math.round(metadata.format.duration! * 1000));
    });
  });
}
```

**`src/vocab-repair.ts`** - Export repaired file list:

```typescript
interface RepairResult {
  totalFiles: number;
  holesFound: number;
  holesRepaired: number;
  holesFailed: number;
  errors: Array<{ filename: string; text: string; error: string }>;
  repairedFiles: Array<{  // NEW
    filename: string;
    text: string;
    audioPath: string;
  }>;
}

// In repairVocabLibrary():
if (repaired) {
  result.holesRepaired++;
  result.repairedFiles.push({  // NEW
    filename: entry.filename,
    text: entry.text,
    audioPath: audioPath
  });
  // ... existing code ...
}
```

**`src/index.ts`** - Call reconstructor after repair:

```typescript
// In main(), after lesson generation:

// Phase 3: Repair vocab holes
console.log('\n' + '='.repeat(60));
console.log('ü©∫ Phase 3: Vocab Repair');
console.log('='.repeat(60) + '\n');

const doctor = new VocabDoctor();
const repairResults: Map<string, RepairResult> = new Map();

for (const langLevel of languageLevels) {
  const [languageId, levelId] = langLevel.split('/');
  const result = await doctor.repairVocabLibrary(languageId, levelId);
  repairResults.set(langLevel, result);
}

// Phase 4: Reconstruct affected lessons (NEW)
console.log('\n' + '='.repeat(60));
console.log('üîß Phase 4: Lesson Reconstruction');
console.log('='.repeat(60) + '\n');

const reconstructor = new LessonReconstructor();

for (const [langLevel, repairResult] of repairResults) {
  if (repairResult.holesRepaired > 0) {
    const [languageId, levelId] = langLevel.split('/');
    console.log(`\nüîç Checking for affected lessons in ${langLevel}...`);
    await reconstructor.reconstructLessons(repairResult, languageId, levelId);
  }
}
```

## Advantages of This Approach

### ‚úÖ Simplicity
- No complex extraction logic
- No segment splicing/joining
- Original silence stays (harmless padding)

### ‚úÖ Efficiency
- Single FFmpeg call per lesson (Option C)
- No re-encoding of good segments
- Fast execution

### ‚úÖ Reliability
- Timestamps from metadata are precise
- No cumulative timing errors
- Easy to verify results

### ‚úÖ Debuggability
- Clear metadata shows what's where
- Can manually test FFmpeg commands
- Audio surgery is audible/testable

## Edge Cases Handled

1. **Multiple holes in same lesson**: Option C handles all at once
2. **Hole at very end**: `adelay` works at any position
3. **Overlapping repairs**: Won't happen (vocab files are unique)
4. **Missing vocab file**: Skip that hole, log warning
5. **Lesson without metadata**: Skip reconstruction, log warning

## Testing Plan

1. **Generate lesson with vocab dependency**
2. **Verify metadata JSON created** with correct segments
3. **Manually corrupt vocab file** (make silent)
4. **Generate lesson** - will have hole
5. **Run vocab-repair** - fixes vocab
6. **Run reconstructor** - injects fixed audio
7. **Listen to repaired lesson** - verify audio plays correctly
8. **Check metadata** - verify repair timestamp recorded

## Performance Estimate

- **Metadata creation**: +50ms per lesson (negligible)
- **Finding affected lessons**: ~10ms per metadata file
- **Audio injection per hole**: ~200-500ms per FFmpeg call
- **Total overhead for 10 lessons with 20 holes**: ~5-10 seconds

**Worth it!** Saves hundreds of API calls and dollars.

---

**This approach is production-ready and maintainable.**

